{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the probability that the model will be at a particular hidden state at time t\n",
    "# Dynamic algorithm that contains for each time step, the probability that the all possible combination of states occured before with the observations times the probability of the specific state and its observed data\n",
    "# o -> observations\n",
    "def forward(o, p_transition, p_emission, pi):\n",
    "\n",
    "    # Start by intitializing a vector of the alphas. This will contain the probabilities of all states at all time t\n",
    "    # Create zero vectore that has rows the length of the observations and columns length as states in the model\n",
    "    # alpha -> forward state probabilities\n",
    "    alpha = np.zeros((o.shape[0], p_transition.shape[0]))\n",
    "\n",
    "    # Set the initial probabilities\n",
    "    alpha[0, :] = pi * p_emission[:, o[0]]\n",
    "\n",
    "    # For all observations ...\n",
    "    for t in range(1, o.shape[0]):\n",
    "        # for all states s_t ...\n",
    "        # (This could be further vectorized)\n",
    "        for s_t in range(p_transition.shape[0]):\n",
    "            # Find the probabilities of the transitions to the states based on previos alpha stored values\n",
    "            # Then multiply by the probability of the observed emission occurring \n",
    "            # \n",
    "            # Vectorized - First part is the summation over all states\n",
    "            alpha[t, s_t] = p_emission[s_t, o[t]] * alpha[t - 1] @ (p_transition[:, s_t])\n",
    "\n",
    "    # So now you basically have whats the probability of seeing each state per time t GIVEN the observable data\n",
    "    return alpha\n",
    "\n",
    "# The same concept but the exact opposite of the forward algorithm\n",
    "# So given a state, what is the probability you see the future data\n",
    "def backward(o, p_transition, p_emission):\n",
    "\n",
    "    # Start by intitializing a vector of the alphas. This will contain the probabilities of all states at all time t\n",
    "    # Create zero vectore that has rows the length of the observations and columns length as states in the model\n",
    "    # beta -> backward state probabilities\n",
    "    beta = np.zeros((o.shape[0], p_transition.shape[0]))\n",
    "\n",
    "    # With Beta, you have to start backward, as that is the only way it makes sense\n",
    "    # So according to the formula, you have to set the last beta value as 1\n",
    "    # Not sure why, but probably just as a starter *** ?\n",
    "    beta[-1] = np.ones((p_transition.shape[0]))\n",
    "\n",
    "    # Then start looping backward from -2 index\n",
    "    # So for all observations ...\n",
    "    for t in range(o.shape[0] - 2, -1, -1): # The 2nd index for stop is -1; excluding\n",
    "        # for all states s_t\n",
    "        # (This could be further vectorized)\n",
    "        for s_t in range(p_transition.shape[0]):\n",
    "            # Find the the \"future\" alphas will emit the observed data and multiply it by the probability that it will transition there\n",
    "            # I 90% understand why its doing this. Look at this again ***\n",
    "            beta[t, s_t] = (beta[t + 1] * p_emission[:, o[t + 1]]).dot(p_transition[s_t, :])\n",
    "\n",
    "    # Returns probability of observing future data given the state at time t\n",
    "    return beta\n",
    "\n",
    "\n",
    "# We cannot see the \"hidden\" states, so this algorithm tries to emulate Maximum Likelihood Estimate\n",
    "# In this view, the transition matrix for hidden state_1 to state_j would be (Expected # of transitions from state_i to state_j) / (Total transitions out of state_i)\n",
    "# The estimated emission matrix given a state_i and observation_o is (Expected # of times state_i output observation_o) / (Total # of times state_i output an observation)\n",
    "# Semi understand what is going on logically, look at this later ***\n",
    "def baum_welch(o, p_transition, p_emission, pi, n=100):\n",
    "    # ALl stuff to iterate over for each step in the algorighm\n",
    "    # Number of states\n",
    "    M = p_transition.shape[0]\n",
    "    # Number of observable data\n",
    "    T = o.__len__()\n",
    "\n",
    "    for _ in range(n):\n",
    "        # Get the forward and backward you need for the E-step\n",
    "        alpha = forward(o, p_transition, p_emission, pi)\n",
    "        beta = backward(o, p_transition, p_emission)\n",
    "        \n",
    "        # This is the E step. In the E steo, you calculate the Xi and the gamma for the M step for all time points\n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        # We first get all the Xi\n",
    "        for t in range(T - 1):\n",
    "            # The lower part of equation vectorized. Includes the probability of getting to the states, the transitioning to the next state then seeing the future observations for all possible combilations of states at each time step\n",
    "            xi_denom = ( (alpha[t, :].T @ p_transition) * p_emission[:, o[t + 1]].T ) @ beta[t + 1, :]\n",
    "            # For all states ...\n",
    "            for i in range(M):\n",
    "                # This is given all possible states that I am in, what is the probability to transition into the next state_j - vectorized\n",
    "                xi_num = alpha[t, i] * p_transition[i, :] * p_emission[:, o[t + 1]].T * beta[t + 1, :].T\n",
    "                # Once both above, divide\n",
    "                xi[i, :, t] = xi_num / xi_denom\n",
    "\n",
    "        # This is the gamma part of the E-step\n",
    "        # quite simple to implement as you sum over all xi, but it is for all states in state_j and not state_i, so i summed over axis 1 not zero *** check\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "\n",
    "        # This is the first part of the M-step\n",
    "        p_transition = np.sum(xi, axis=2) / np.sum(gamma, axis=1).reshape((-1, 1)) # reshape to make it 2 dimentional be its just all the values in vector form and not list form\n",
    "\n",
    "        # Keep getting this error: IndexError: boolean index did not match indexed array along dimension 1; dimension is 299 but corresponding boolean dimension is 300\n",
    "        # So I assume I need to add another gamma. Idk why \n",
    "        # Oh, this is not needed for p_transition as that only goes up till T-1 but for p_emissions, it goes up to T\n",
    "        # where to I get the last T values though?\n",
    "        # Add additional T'th values in gamma because we went up toll T - 1 as same as above\n",
    "        # T - 1 is 0s\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=1).reshape((-1, 1))))\n",
    "\n",
    "        # Sum over all time\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        denominator = denominator.reshape((-1, 1))\n",
    "        # For all possible emissions\n",
    "        for m in range(p_emission.shape[1]):\n",
    "            # generate a mask to only index the emission values for when I am in the correct emission value\n",
    "            bool_mask = (o == m)\n",
    "            # Get each emission value for the right observed value\n",
    "            p_emission[:, m] = np.sum(gamma[:, bool_mask], axis=1)\n",
    "\n",
    "        p_emission = np.divide(p_emission, denominator)\n",
    "\n",
    "    return p_transition, p_emission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "# Generate Data\n",
    "\n",
    "# Initial state probabilities\n",
    "pi = np.array([0.5, 0.5])\n",
    "\n",
    "# Transition Probabilities for the state\n",
    "# 2 states\n",
    "p_transition = np.array([\n",
    "    [0.6, 0.4],\n",
    "    [0.4, 0.6]\n",
    "])\n",
    "\n",
    "# Emission Probabilities\n",
    "# 3 Observable variables\n",
    "p_emission = np.array([\n",
    "    [0.2, 0.4, 0.4],\n",
    "    [0.5, 0.1, 0.4]\n",
    "])\n",
    "\n",
    "def generate_data_multinomial(states, p_transition, p_emission, n=100, pi=None, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Generate an initial state probability if no pi given\n",
    "    if type(pi) == \"NoneType\":\n",
    "        pi = np.random.dirichlet(np.ones(states))\n",
    "    \n",
    "    # A list of the states\n",
    "    s = []\n",
    "    \n",
    "    # First get the initial state\n",
    "    s.append(np.argmax(multinomial.rvs(n=1, p=pi)))\n",
    "    \n",
    "    # Generate all the other states\n",
    "    for _ in range(1, n):\n",
    "        s.append(\n",
    "            np.argmax(\n",
    "                # The probability is based on the last state\n",
    "                multinomial.rvs(n=1, p=p_transition[s[-1]])\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # A list of all the emissions\n",
    "    e = []\n",
    "    \n",
    "    # Generate all the emissions\n",
    "    for n in range(n):\n",
    "        e.append(\n",
    "            np.argmax(\n",
    "                # This is the same as for the generating states but with p_emission\n",
    "                multinomial.rvs(n=1, p=p_emission[s[-1]])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Return the states and emissions\n",
    "    return s, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial state probabilities\n",
    "pi = np.array([0.5, 0.5])\n",
    "\n",
    "# Transition Probabilities for the state\n",
    "# 2 states\n",
    "p_transition = np.array([\n",
    "    [0.6, 0.4],\n",
    "    [0.4, 0.6]\n",
    "])\n",
    "\n",
    "# Emission Probabilities\n",
    "# 3 Observable variables\n",
    "p_emission = np.array([\n",
    "    [0.2, 0.4, 0.4],\n",
    "    [0.5, 0.1, 0.4]\n",
    "])\n",
    "s, e = generate_data_multinomial(2, p_transition, p_emission, n=300, pi=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_transition_matrix, p_emission_matrix = baum_welch(np.array(e), p_transition, p_emission, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05229412, 0.41352448, 0.5341814 ],\n",
       "       [0.40446124, 0.36412521, 0.23141356]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
